{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campito Mountain Bristlecone Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses raw ring widths for bristlecone pine (_Pinus longaeva_) at Campito Mountain in California, USA. This is one of the datasets included in `dplR` as well and include in the dplPy distribution.\n",
    "\n",
    "> Graybill, D. A. and LaMarche, Jr., V. C. (1983) Campito Mountain Data Set. IGBP PAGES/World Data Center for Paleoclimatology Data Contribution Series 1983-CA533.RWL. NOAA/NCDC Paleoclimatology Program, Boulder, Colorado, USA: https://www.ncei.noaa.gov/pub/data/paleo/treering/measurements/northamerica/usa/ca533.rwl\n",
    "\n",
    "Let's start by importing some standard Python libraries.  We'll bring in Pandas (for working with 2 dimensional data), Matplotlib to help with plotting,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# the following two lines nicely render figures in the notebook \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# you can omit the line below if you'd like, but I really don't like the default fonts in Python, so I switch to Helvetica\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update (or install) `dplpy` directly from this notebook if necessary using the 'bang' (`!`) command - you can just skip this code block or comment it out if you're already running the latest version from the Pypi repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if necessary, install dplpy\n",
    "# !pip install dplpy\n",
    "\n",
    "# if necessary upgrade dplpy to the latest version, v0.1.2 as of January 8th, 2024\n",
    "# !pip install dplpy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let us now import `dplpy` and we'll check the version number and see where the library is on our system.  If everything is working well, the codeblock should complete without error and you should see that you are running v0.1.2 from one of your Python directories (you will see `/envs/` in the path if you are in a virtual environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dplpy as dpl\n",
    "\n",
    "# print out the version number of dplPy you are using - should be v0.1.2 \n",
    "print('Currently using the following version of dplPy:', dpl.__version__)\n",
    "\n",
    "# You should see the path to your local Python installation\n",
    "print('Currently using the following directory for dplPy:', dpl.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the Campito Mountain raw measurement series into our notebook now.  We will use the `dpl.readers` method to do this.  For the moment, `.readers` automatically identified the file type from the file suffix, looking for `.rwl` for Tucson formatted decadal files, or `.csv`.  In the future, the method will recognize a wider variety of suffixes (e.g. `.raw`), allow you to pass the file type directly to the method, or pull from the ITRDB.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Campito Mountain series and assign to a variable\n",
    "ca533 = dpl.readers(\"ca533.rwl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the DataFrame\n",
    "ca533 #1358 years by 34 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also read in the Sheep Mountain update (`ca667.rwl`).  This file has headers, though - we tell `.readers` about the existence of the Tucson style (3 line) headers when we call `.readers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can specify whether file has headers so reading of data is done appropriately\n",
    "ca667 = dpl.readers(\"ca667.rwl\", header=True)\n",
    "ca667 # 310 columns, 4655 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ca533.index) # Campito Mountain chronology covers 626 to 1983\n",
    "print(ca667.index)  # Campito Mountain chronology covers -2649 (BCE) to 2005!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could, if we wanted, use Pandas to merge the two datasets to form a combined Sheep-Campito Mountain chronology.  The codeblock below shows how to use Pandas [.merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) to do this.  Because this creates a very large and very long set of series, we won't use this in the rest of the notebook, but it is useful to see how you might do this.  Of note is that the `.merge` function is NOT unique to `dplpy` - following the overall philosophy also adopted for dplR, we don't create functions with openDendro to do common data manipulations or data handling (e.g. things that are not specific to dendrochronology): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shpcmp = pd.merge(ca533, ca667, left_index=True, right_index=True, how='outer') # this is just a pure Pandas command\n",
    "shpcmp # pretty-print from Pandas will show 4655 years x 344 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to Campito Mountain (`ca533`)now.  Our `dplpy` provides both `.summary` statistics (the individual series mean, quantiles, max and min values) as well as the `.statistics` of the individual series including first and last year, mean, median, standard deviation, skew, gini coefficient and AR1 coefficient similar to ARSTAN.  The module names follow those in `dplR` and report complementary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl.summary(ca533)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl.stats(ca533)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another module available is the `.report`, which has information similar to that provided by COFECHA and mirrors the similar function in dplR, including the years with locally absent rings in each individual series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get a report of some of the essential features of this dataset from .report\n",
    "dpl.report(ca533)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in dplR, we can readily `.plot` spaghetti (`type=\"spag\"`) or segment (`type=\"seg\"`) plots.  Note that `.plot` here is a method attached to the core `dplpy` library.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl.plot(ca533, type=\"seg\")\n",
    "dpl.plot(ca533, type=\"spag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, detrending is one of the most important functions of DPL.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca533_rwi = dpl.detrend(ca533, fit=\"spline\", period=200, method=\"residual\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam161_spline67 = dpl.detrend(ca533[\"CAM161\"], fit=\"spline\", period=-67,method=\"residual\", plot=True)\n",
    "cam161_negex = dpl.detrend(ca533[\"CAM161\"], fit=\"Hugershoff\", method=\"difference\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca533_crn_std = dpl.chron(ca533_rwi, biweight=True, prewhiten=False, plot=True)\n",
    "ca533_crn_res = dpl.chron(ca533_rwi, biweight=True, prewhiten=True, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossdating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl.xdate(ca533_rwi, prewhiten=True, corr=\"Spearman\", slide_period=50, bin_floor=10, p_val=0.05, show_flags=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl.series_corr(ca533_rwi, \"CAM181\", prewhiten=True, corr=\"Spearman\", seg_length=50, bin_floor=10, p_val=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a8dfe095fce2b5e88c64a2c3ee084c8e0e0d70b23e7b95b1cfb538be294c5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
